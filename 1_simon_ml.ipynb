{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Pipeline fMRI dataset for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CORE LIBRARIES (FMRI + ML + GLM + DATA)\n",
    "import os\n",
    "import glob \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nilearn\n",
    "import sklearn\n",
    "from nilearn import image, plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "\n",
    "print(\"Nilearn:\", nilearn.__version__)\n",
    "print(\"OK, todo carg√≥, imports fMRI listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET DATASET ROOT DIRECTORY\n",
    "\n",
    "base_path = \"/Users/antoniaolgui/Library/Mobile Documents/com~apple~CloudDocs/Desktop/simon_ml/ds101_R2.0.0/\"\n",
    "\n",
    "# List folder contents (should show sub-01, sub-02, ...)\n",
    "os.listdir(base_path)\n",
    "\n",
    "#Get sorted list of all subject in the dataset\n",
    "subjects = sorted([d for d in os.listdir(base_path) if d.startswith(\"sub-\")])\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK UNIQUE trial_type VALUES ACROSS ALL EVENT FILES\n",
    "# (This reveals how congruency and correctness are encoded)\n",
    "\n",
    "pattern = os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "trial_types = set()\n",
    "\n",
    "for f in files:\n",
    "    df_tmp = pd.read_csv(f, sep=\"\\t\")\n",
    "    trial_types.update(df_tmp[\"trial_type\"].unique())\n",
    "\n",
    "trial_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MASTER BEHAVIORAL DATAFRAME\n",
    "#    - Reads all *_events.tsv files from all subjects\n",
    "#    - Extracts congruency (congruent / incongruent)\n",
    "#    - Extracts accuracy (correct / incorrect)\n",
    "#    - Creates binary ML label (0 = congruent, 1 = incongruent)\n",
    "\n",
    "pattern = os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "print(\"Number of event files found:\", len(files))\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "    # Extract subject ID and run filename\n",
    "    subject = f.split(\"/\")[-3]\n",
    "    run = f.split(\"/\")[-1]\n",
    "    \n",
    "    df[\"subject\"] = subject\n",
    "    df[\"run\"] = run\n",
    "    \n",
    "    # Add continuous trial number within each run\n",
    "    df[\"trial\"] = range(1, len(df) + 1)\n",
    "    \n",
    "    # trial_type format: \"congruent_correct\", \"incongruent_incorrect\"\n",
    "    df[\"congruency\"] = df[\"trial_type\"].str.split(\"_\").str[0]\n",
    "    df[\"accuracy_label\"] = df[\"trial_type\"].str.split(\"_\").str[1]\n",
    "\n",
    "    # Binary label for ML\n",
    "    df[\"label\"] = df[\"congruency\"].map({\"congruent\": 0, \"incongruent\": 1})\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df_clean = df[[\n",
    "        \"subject\",\n",
    "        \"run\",\n",
    "        \"trial\",\n",
    "        \"trial_type\",\n",
    "        \"congruency\",\n",
    "        \"accuracy_label\",\n",
    "        \"correctness\",\n",
    "        \"StimVar\",\n",
    "        \"behav_unlabeled\",\n",
    "        \"Rsponse\",\n",
    "        \"Stimulus\",\n",
    "        \"cond\",\n",
    "        \"label\"\n",
    "    ]]\n",
    "    \n",
    "    all_rows.append(df_clean)\n",
    "\n",
    "behaviour = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "behaviour.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CLEAN DATASET + BASIC DESCRIPTIVE STATS\n",
    "behaviour.to_csv(\"/Users/antoniaolgui/Desktop/simon_ml/simon_behaviour_clean.csv\", \n",
    "                 index=False)\n",
    "\n",
    "print(\"DataFrame shape:\", behaviour.shape)\n",
    "\n",
    "print(\"\\nTrials per congruency:\")\n",
    "print(behaviour[\"congruency\"].value_counts())\n",
    "\n",
    "print(\"\\nTrials per subject:\")\n",
    "print(behaviour[\"subject\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summarized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of trials per subject\n",
    "\n",
    "behaviour[behaviour[\"subject\"] == \"sub-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per-subject summary including congruency distribution\n",
    "\n",
    "behaviour.groupby(\"subject\").agg({\n",
    "    \"trial\": \"count\",\n",
    "    \"congruency\": lambda x: x.value_counts().to_dict()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabla maestra bonita con TODOS los sujetos ‚Äúordenados‚Äù\n",
    "behaviour.sort_values([\"subject\", \"run\", \"trial\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Machine Learning Pipeline - SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN CON 80-20\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Features y label (igual que antes)\n",
    "X = behaviour[[\"correctness\", \"Rsponse\", \"Stimulus\", \"cond\", \"StimVar\", \"accuracy_label\"]]\n",
    "y = behaviour[\"label\"]  # 0 = congruent, 1 = incongruent\n",
    "\n",
    "# Grupos = sujeto\n",
    "groups = behaviour[\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Todas las features son categ√≥ricas en este caso\n",
    "categorical_features = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# ==== GroupShuffleSplit: splits por sujeto ====\n",
    "gss = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "split_id = 1\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Split {split_id} - Accuracy: {acc:.3f}\")\n",
    "    split_id += 1\n",
    "\n",
    "print(\"\\nMean accuracy across splits:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN CON LOS 21 SUJETOS NO M√ÅS, BASICAMENTE PERFECTO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Copy of the dataframe for ML\n",
    "df_ml = behaviour.copy()\n",
    "\n",
    "# Features and label\n",
    "X = df_ml[[\"correctness\", \"Rsponse\", \"Stimulus\", \"cond\", \"StimVar\", \"accuracy_label\"]]\n",
    "y = df_ml[\"label\"]   # 0 = congruent, 1 = incongruent\n",
    "\n",
    "# Treat ALL features as categorical\n",
    "categorical_features = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train‚Äìtest split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Machine Learning Pipeline - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train/test split (ya lo debes tener hecho)\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"üîµ RANDOM FOREST RESULTS\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Visualization of brain images in fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_file = f\"{base_path}/sub-01/func/sub-01_task-simon_run-1_bold.nii\"\n",
    "img = image.load_img(fmri_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_file = f\"{base_path}/sub-01/func/sub-01_task-simon_run-1_bold.nii\"\n",
    "img = image.load_img(fmri_file)\n",
    "\n",
    "# 1) Promedio temporal ‚Üí imagen 3D\n",
    "mean_img = image.mean_img(img)\n",
    "\n",
    "# 2) Plot bonito\n",
    "plotting.plot_epi(mean_img, display_mode=\"ortho\",\n",
    "                  title=\"sub-01 Run 1 - Mean BOLD\")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(mean_img, threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## GLM FIRST LEVEL : Congruent vs Incongruent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image, plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "\n",
    "# CONFIGURACI√ìN \n",
    "base_path = \"/Users/antoniaolgui/Library/Mobile Documents/com~apple~CloudDocs/Desktop/simon_ml/ds101_R2.0.0/\"\n",
    "TR = 2.0\n",
    "runs = [1, 2]\n",
    "\n",
    "# carpeta donde quedan guardado los mapas z por sujeto\n",
    "output_dir = \"first_level_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def map_congruency(tt):\n",
    "    tt = str(tt).lower()\n",
    "    if \"incongruent\" in tt:\n",
    "        return \"incongruent\"\n",
    "    elif \"congruent\" in tt:\n",
    "        return \"congruent\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "subjects = [f\"sub-{i:02d}\" for i in range(1, 22)]   # sub-01 ... sub-21\n",
    "\n",
    "for subject in subjects:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Procesando:\", subject)\n",
    "    print(\"==============================\")\n",
    "\n",
    "    fmri_imgs = []\n",
    "    design_matrices = []\n",
    "\n",
    "    for run in runs:\n",
    "        # Cargar data fMRI \n",
    "        fmri_file = os.path.join(\n",
    "            base_path,\n",
    "            subject,\n",
    "            \"func\",\n",
    "            f\"{subject}_task-simon_run-{run}_bold.nii.gz\"\n",
    "        )\n",
    "        img = image.load_img(fmri_file)\n",
    "        fmri_imgs.append(img)\n",
    "\n",
    "        n_scans = img.shape[-1]\n",
    "        frame_times = np.arange(n_scans) * TR\n",
    "\n",
    "        # Cargar eventos y recodificar \n",
    "        events_file = os.path.join(\n",
    "            base_path,\n",
    "            subject,\n",
    "            \"func\",\n",
    "            f\"{subject}_task-simon_run-{run}_events.tsv\"\n",
    "        )\n",
    "        events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "        events[\"trial_type\"] = events[\"trial_type\"].apply(map_congruency)\n",
    "        events = events[events[\"trial_type\"].notna()]  # elimina trial types que no sean congruent/incongruent\n",
    "\n",
    "        # Construcci√≥n de la matriz de dise√±o (HRF Glover, drift coseno, high-pass)\n",
    "        design = make_first_level_design_matrix(\n",
    "            frame_times=frame_times,\n",
    "            events=events,\n",
    "            hrf_model=\"glover\",\n",
    "            drift_model=\"cosine\",\n",
    "            high_pass=0.01\n",
    "        )\n",
    "        design_matrices.append(design)\n",
    "\n",
    "    # Ajuste del modelo GLM de primer nivel\n",
    "    glm = FirstLevelModel(\n",
    "        t_r=TR,\n",
    "        smoothing_fwhm=5.0,\n",
    "        minimize_memory=True\n",
    "    ).fit(fmri_imgs, design_matrices=design_matrices)\n",
    "\n",
    "    # Contraste entre condiciones congruente e incognruente\n",
    "    z_map = glm.compute_contrast(\"incongruent - congruent\", output_type=\"z_score\")\n",
    "\n",
    "    # Guardar mapas Z\n",
    "    out_path = os.path.join(output_dir, f\"{subject}_zmap_incongruent_vs_congruent.nii.gz\")\n",
    "    z_map.to_filename(out_path)\n",
    "    print(f\"Mapa guardado en: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLICE CENTRAL DE 1 SUJETO PARA VISUALIZAR\n",
    "#mapa Z es la diferencia entre ambas condici√≥nes congruente e incongruente, pero se puede hacer uno para cada condicion por sujeto\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "\n",
    "# carga un mapa Z de un sujeto\n",
    "z_map = image.load_img(\"first_level_results/sub-01_zmap_incongruent_vs_congruent.nii.gz\")\n",
    "\n",
    "data = z_map.get_fdata()   # esto es un array 3D\n",
    "\n",
    "# elegir un corte (slice)\n",
    "slice_idx = data.shape[2] // 2  # corte sagital/axial central\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(data[:, :, slice_idx], cmap='bwr', origin='lower')\n",
    "plt.colorbar(label=\"Z value\")\n",
    "plt.title(\"Mapa Z (slice central)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (signalanalysis)",
   "language": "python",
   "name": "signalanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
