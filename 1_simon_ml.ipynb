{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd679ba-4e08-419d-a66d-37911ce76adc",
   "metadata": {},
   "source": [
    "## Pipeline fMRI dataset for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab715c9-961a-494b-bcdb-8c19119e1326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35435a0e-025f-43d8-8a56-9a5b781082a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CORE LIBRARIES (FMRI + ML + DATA\n",
    "# Neuro / ML / manejo de datos\n",
    "import nilearn\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "# Utilidades del sistema de archivos\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"Nilearn:\", nilearn.__version__)\n",
    "print(\"OK, todo carg√≥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081a1ad-fcf1-4333-b976-015d589c965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET DATASET ROOT DIRECTORY\n",
    "\n",
    "base_path = \"/Users/antoniaolgui/Library/Mobile Documents/com~apple~CloudDocs/Desktop/ds101_R2.0.0/\"\n",
    "\n",
    "# List folder contents (should show sub-01, sub-02, ...)\n",
    "os.listdir(base_path)\n",
    "\n",
    "#Get sorted list of all subject in the dataset\n",
    "subjects = sorted([d for d in os.listdir(base_path) if d.startswith(\"sub-\")])\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d34015-d7c7-43f4-8e5f-3996702283e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK UNIQUE trial_type VALUES ACROSS ALL EVENT FILES\n",
    "#    (This reveals how congruency and correctness are encoded)\n",
    "\n",
    "pattern = os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "trial_types = set()\n",
    "\n",
    "for f in files:\n",
    "    df_tmp = pd.read_csv(f, sep=\"\\t\")\n",
    "    trial_types.update(df_tmp[\"trial_type\"].unique())\n",
    "\n",
    "trial_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e03bb-1b37-474d-bf06-30082c6b1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MASTER BEHAVIORAL DATAFRAME\n",
    "#    - Reads all *_events.tsv files from all subjects\n",
    "#    - Extracts congruency (congruent / incongruent)\n",
    "#    - Extracts accuracy (correct / incorrect)\n",
    "#    - Creates binary ML label (0 = congruent, 1 = incongruent)\n",
    "\n",
    "pattern = os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "print(\"Number of event files found:\", len(files))\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "    # Extract subject ID and run filename\n",
    "    subject = f.split(\"/\")[-3]\n",
    "    run = f.split(\"/\")[-1]\n",
    "    \n",
    "    df[\"subject\"] = subject\n",
    "    df[\"run\"] = run\n",
    "    \n",
    "    # Add continuous trial number within each run\n",
    "    df[\"trial\"] = range(1, len(df) + 1)\n",
    "    \n",
    "    # trial_type format: \"congruent_correct\", \"incongruent_incorrect\"\n",
    "    df[\"congruency\"] = df[\"trial_type\"].str.split(\"_\").str[0]\n",
    "    df[\"accuracy_label\"] = df[\"trial_type\"].str.split(\"_\").str[1]\n",
    "\n",
    "    # Binary label for ML\n",
    "    df[\"label\"] = df[\"congruency\"].map({\"congruent\": 0, \"incongruent\": 1})\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df_clean = df[[\n",
    "        \"subject\",\n",
    "        \"run\",\n",
    "        \"trial\",\n",
    "        \"trial_type\",\n",
    "        \"congruency\",\n",
    "        \"accuracy_label\",\n",
    "        \"correctness\",\n",
    "        \"StimVar\",\n",
    "        \"behav_unlabeled\",\n",
    "        \"Rsponse\",\n",
    "        \"Stimulus\",\n",
    "        \"cond\",\n",
    "        \"label\"\n",
    "    ]]\n",
    "    \n",
    "    all_rows.append(df_clean)\n",
    "\n",
    "behaviour = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "behaviour.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c4eaf-0c7c-4cb0-b67c-2f9ed742fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CLEAN DATASET + BASIC DESCRIPTIVE STATS\n",
    "\n",
    "behaviour.to_csv(\"simon_behaviour_clean.csv\", index=False)\n",
    "\n",
    "print(\"DataFrame shape:\", behaviour.shape)\n",
    "\n",
    "print(\"\\nTrials per congruency:\")\n",
    "print(behaviour[\"congruency\"].value_counts())\n",
    "\n",
    "print(\"\\nTrials per subject:\")\n",
    "print(behaviour[\"subject\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee8c9e-ed4c-4a5d-8c79-b6c0e0e37a5f",
   "metadata": {},
   "source": [
    "### Summarized tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a0580-8b38-4da2-8daa-797d7e16c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of trials per subject\n",
    "\n",
    "behaviour[behaviour[\"subject\"] == \"sub-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea7dac-269a-409a-984b-e4b9645635a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per-subject summary including congruency distribution\n",
    "\n",
    "behaviour.groupby(\"subject\").agg({\n",
    "    \"trial\": \"count\",\n",
    "    \"congruency\": lambda x: x.value_counts().to_dict()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e60ab-5f38-4ed5-87f6-ab9a2dc2d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabla maestra bonita con TODOS los sujetos ‚Äúordenados‚Äù\n",
    "behaviour.sort_values([\"subject\", \"run\", \"trial\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e57dd-f304-498c-96bf-cc5c52715a25",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf00dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour = pd.read_csv(\"simon_behaviour_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4354e-8b3c-47a3-958a-30b72dac0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN CON 80-20\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Features y label (igual que antes)\n",
    "X = behaviour[[\"correctness\", \"Rsponse\", \"Stimulus\", \"cond\", \"StimVar\", \"accuracy_label\"]]\n",
    "y = behaviour[\"label\"]  # 0 = congruent, 1 = incongruent\n",
    "\n",
    "# Grupos = sujeto\n",
    "groups = behaviour[\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8036d-3e59-4470-b0da-3fc434c7f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Todas las features son categ√≥ricas en este caso\n",
    "categorical_features = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# ==== GroupShuffleSplit: splits por sujeto ====\n",
    "gss = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "split_id = 1\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Split {split_id} - Accuracy: {acc:.3f}\")\n",
    "    split_id += 1\n",
    "\n",
    "print(\"\\nMean accuracy across splits:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aab83b-9858-4b20-a9b8-4ab2a2ff1e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb3afc-fad5-4110-8f09-0f69ff6b0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN CON LOS 21 SUJETOS NO M√ÅS, BASICAMENTE PERFECTO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Copy of the dataframe for ML\n",
    "df_ml = behaviour.copy()\n",
    "\n",
    "# Features and label\n",
    "X = df_ml[[\"correctness\", \"Rsponse\", \"Stimulus\", \"cond\", \"StimVar\", \"accuracy_label\"]]\n",
    "y = df_ml[\"label\"]   # 0 = congruent, 1 = incongruent\n",
    "\n",
    "# Treat ALL features as categorical\n",
    "categorical_features = X.columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train‚Äìtest split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf4c56-f6b6-4f1e-93e5-9b7f40c51c53",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2994a-1ea1-4d26-a694-3926b12bb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train/test split (ya lo debes tener hecho)\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"üîµ RANDOM FOREST RESULTS\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e457c97-8ce5-414d-a28f-d3fedfe9dc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b27864ec-bf4c-478e-9d90-28ef4f3fda93",
   "metadata": {},
   "source": [
    "# Visualization of brain images in fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b1ebf-cc89-4daa-998e-82fbb4538f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a9800-9a58-4b8a-85b1-cc64d887ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_file = f\"{base_path}/sub-01/func/sub-01_task-simon_run-1_bold.nii\"\n",
    "img = image.load_img(fmri_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424c1e6-7aad-45d7-84a4-efb4db48f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90a6d7-bdb0-4d56-b40c-6a77570536ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_file = f\"{base_path}/sub-01/func/sub-01_task-simon_run-1_bold.nii\"\n",
    "img = image.load_img(fmri_file)\n",
    "\n",
    "# 1) Promedio temporal ‚Üí imagen 3D\n",
    "mean_img = image.mean_img(img)\n",
    "\n",
    "# 2) Plot bonito\n",
    "plotting.plot_epi(mean_img, display_mode=\"ortho\",\n",
    "                  title=\"sub-01 Run 1 - Mean BOLD\")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a7259-57f8-4c12-aab2-f2ec030aeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(mean_img, threshold=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurocomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
