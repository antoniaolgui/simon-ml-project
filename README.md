# Simon fMRI – First-level GLM Analysis

This repository contains a reproducible fMRI analysis pipeline for the **Simon Task** dataset from Stanford (`ds101`, "Simon task dataset").

The main goal is to compute **first-level General Linear Models (GLM)** for each subject using **Nilearn**, starting from the raw BIDS-formatted data and producing individual Z-maps for the contrast **incongruent > congruent**.

Original dataset:
- Stanford Digital Repository: https://exhibits.stanford.edu/data/catalog/zs514nn4996

---

## Repository Structure

- `environment.yml`  
	Conda environment specification with all dependencies required to run the notebooks.

- `simon_task.ipynb`  
	Main notebook that implements the **first-level GLM analysis** for all 21 subjects of the Simon Task.

- `ml_conditions.ipynb`  
	(Optional) Notebook that uses trial-wise brain patterns to perform a **machine learning decoding** analysis (SVM classifier) for Congruent vs Incongruent trials.

- `simon_behaviour_clean.csv`  
	Cleaned behavioral dataset generated by `simon_task.ipynb`, containing trial-level information for all subjects.

- `data/`  
	Folder where the **BIDS dataset** must be placed. The expected structure is:

	```text
	data/
		ds101_R2.0.0/
			sub-01/
				anat/
				func/
					sub-01_task-simon_run-1_bold.nii
					sub-01_task-simon_run-1_events.tsv
					sub-01_task-simon_run-2_bold.nii
					sub-01_task-simon_run-2_events.tsv
			sub-02/
				anat/
				func/
					...
			...
			sub-21/
				anat/
				func/
	```

- `first_level_results/`  
	Output directory containing the **first-level Z-maps** for each subject and contrast, e.g.:

	```text
	first_level_results/
		sub-01_zmap_incongruent_vs_congruent.nii.gz
		sub-01_zmap_congruent_vs_incongruent.nii.gz
		sub-01_zmap_incongruent.nii.gz
		sub-01_zmap_congruent.nii.gz
		sub-01_zmap_task_activation.nii.gz
		...
		sub-21_zmap_incongruent_vs_congruent.nii.gz
	```

- `first_level_reports/`  
	Folder containing **interactive HTML reports** generated by Nilearn’s `FirstLevelModel.generate_report` for each subject. Each report includes:
	- The design matrices for both runs.
	- Correlation plots between regressors.
	- Statistical maps for the main contrasts (including *incongruent > congruent*).

---

## Environment Setup

This project is designed to run in a **Conda environment** defined in `environment.yml`.

### 1. Create and activate the environment

```bash
conda env create -f environment.yml
conda activate neurocomp
```

If you prefer `mamba`:

```bash
mamba env create -f environment.yml
conda activate neurocomp
```

### 2. Register the Jupyter kernel (optional but recommended)

```bash
python -m ipykernel install --user --name neurocomp --display-name "Python (neurocomp)"
```

### 3. Launch Jupyter

```bash
jupyter notebook
```

Then open `simon_task.ipynb` from the Jupyter interface.

---

## Data Requirements

Download the **Simon Task dataset (ds101)** from the Stanford link above and place it under `data/` so that the path matches the configuration used in the notebooks:

```python
base_path = "data/ds101_R2.0.0/"
```

The notebooks assume the dataset follows the **BIDS** structure shown in the Repository Structure section.

> Note: The dataset used here is **raw** (not preprocessed). The first-level GLM is run directly on these native-space images. For more advanced analyses (e.g., group-level inference), spatial normalization to a standard template (e.g., MNI) is recommended.

---

## `simon_task.ipynb`: First-level GLM

This notebook implements the **first-level fMRI analysis** for the Simon Task using Nilearn’s `FirstLevelModel`.

### Main steps

1. **Environment and configuration**  
	 - Imports `numpy`, `pandas`, `matplotlib`, and Nilearn modules (`image`, `plotting`, `FirstLevelModel`, `make_first_level_design_matrix`).  
	 - Sets the dataset path (`base_path = "data/ds101_R2.0.0/"`), the repetition time (`TR = 2.0 s`) and the list of runs (`[1, 2]`).

2. **Behavioral data inspection**  
	 - Loads all `*_events.tsv` files across subjects.  
	 - Concatenates them into a single DataFrame (`behaviour`) to inspect the distribution of `trial_type` and trials per subject.

3. **Behavioral data cleaning**  
	 - Processes each events file to extract:
		 - Subject ID, run, and trial number.  
		 - `congruency` (congruent vs incongruent) and `accuracy_label` (correct/incorrect) from `trial_type`.  
		 - A binary label `label` for ML (0 = congruent, 1 = incongruent).  
	 - Saves the cleaned dataset as `simon_behaviour_clean.csv` in the project root.

4. **Helper functions and subject list**  
	 - Defines `map_congruency(tt)` to recode `trial_type` into `"congruent"` or `"incongruent"`, discarding other events.  
	 - Defines the list of subjects: `sub-01` to `sub-21`.

5. **Dry run: Data loading verification**  
	 - Loops over all subjects and both runs to:
		 - Load the BOLD images.  
		 - Load and recode the events.  
		 - Build a design matrix per run using `make_first_level_design_matrix` with:
			 - HRF model: `"glover"`.  
			 - Drift model: `"cosine"`.  
			 - High-pass filter: `0.01 Hz`.  
	 - This step checks that all files are present and correctly formatted.

6. **Diagnostics on a single subject (`sub-01`)**  
	 - Fits separate GLMs for Run 1 and Run 2 of `sub-01` using `FirstLevelModel`.  
	 - Computes the contrast `"incongruent - congruent"` for each run and visualizes the resulting Z-maps.  
	 - This allows a quick quality check before running the full analysis.

7. **First-level GLM (Joint Model) for all subjects**  
	 - For each subject:
		 - Loads both runs’ BOLD images and events.  
		 - Builds a design matrix for each run with the same GLM settings (Glover HRF, cosine drift, high-pass 0.01 Hz).  
		 - Fits a **joint GLM** across both runs with `FirstLevelModel(t_r=TR, smoothing_fwhm=5.0, minimize_memory=True, n_jobs=-1)`.  
	 - Defines a set of T-contrasts:
		 - `incongruent_vs_congruent = "incongruent - congruent"`  
		 - `congruent_vs_incongruent = "congruent - incongruent"`  
		 - `incongruent = "incongruent"`  
		 - `congruent = "congruent"`  
		 - `task_activation = "incongruent + congruent"`  
	 - Adds an F-contrast `effects_of_interest` capturing the main conditions.  
	 - Generates a **HTML report** per subject via `glm.generate_report(...)` and saves it in `first_level_reports/` (one file per subject, e.g. `report_sub-01.html`). These reports allow you to visually inspect the design matrices, correlations and activation maps without re-running the notebook.  
	 - Computes Z-maps for all defined contrasts using `glm.compute_contrast(..., output_type="z_score")` and saves them in `first_level_results/` with filenames like:
		 - `sub-01_zmap_incongruent_vs_congruent.nii.gz`.

8. **Result inspection and visualization**  
	 - Lists the contents of `first_level_results/`.  
	 - Loads and plots an example Z-map (e.g. `sub-05_zmap_incongruent_vs_congruent.nii.gz`).  
	 - Displays a central axial slice of a Z-map as a 2D matrix and plots the histogram of Z-values to inspect the statistical distribution.  
	 - Includes a quick visualization of a mean BOLD image to confirm that the dataset is in raw (non–skull-stripped) space.

---

## Reproducibility Checklist

To fully reproduce the first-level GLM analysis:

1. Clone this repository:

	 ```bash
	 git clone <this-repo-url>
	 cd simon-ml-project
	 ```

2. Download the Simon Task dataset (`ds101`) from:  
	 https://exhibits.stanford.edu/data/catalog/zs514nn4996  
	 and place it under `data/ds101_R2.0.0/` as described above.

3. Create and activate the Conda environment:

	 ```bash
	 conda env create -f environment.yml
	 conda activate neurocomp
	 ```

4. Launch Jupyter and open `simon_task.ipynb`:

	 ```bash
	 jupyter notebook
	 ```

5. Run all cells in order.  
	 This will:
	 - Generate `simon_behaviour_clean.csv`.  
	 - Produce first-level Z-maps for all subjects in `first_level_results/`.  
	 - Create interactive HTML reports in `first_level_reports/`.