{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c408cd",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Import libraries for neuroimaging (Nilearn), machine learning (Scikit-learn), and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn import image, plotting, decoding\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from nilearn.input_data import NiftiMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f11e3",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Define dataset paths and parameters. We will focus on a single subject (e.g., `sub-01`) for this demonstration, but the logic applies to all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "base_path = \"data/ds101_R2.0.0/\"\n",
    "subject = \"sub-01\"\n",
    "TR = 2.0\n",
    "runs = [1, 2]\n",
    "\n",
    "print(f\"Analyzing Subject: {subject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c771a",
   "metadata": {},
   "source": [
    "## 3. Data Preparation for ML\n",
    "Unlike standard GLM which models the whole time series, for decoding we often want **one sample per trial** (or per block).\n",
    "\n",
    "**Strategy:**\n",
    "1. Load the fMRI time series.\n",
    "2. Load the events and identify the onset of each trial.\n",
    "3. Extract the specific fMRI volume (scan) corresponding to each trial onset (accounting for hemodynamic lag, approx 4-6s).\n",
    "4. Create a list of `X` (brain images) and `y` (labels: congruent/incongruent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6422bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to map trial types\n",
    "def map_congruency(tt):\n",
    "    tt = str(tt).lower()\n",
    "    if \"incongruent\" in tt:\n",
    "        return \"incongruent\"\n",
    "    elif \"congruent\" in tt:\n",
    "        return \"congruent\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Lists to hold our dataset\n",
    "conditions = []\n",
    "run_labels = []\n",
    "fmri_volumes = []\n",
    "\n",
    "# We need a mask to extract data from the brain only\n",
    "# We'll compute a simple mask from the first run\n",
    "mask_img = decoding.compute_mask(os.path.join(base_path, subject, \"func\", f\"{subject}_task-simon_run-1_bold.nii.gz\"))\n",
    "\n",
    "print(\"Extracting trial data...\")\n",
    "\n",
    "for run in runs:\n",
    "    # 1. Load fMRI image\n",
    "    fmri_file = os.path.join(base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_bold.nii.gz\")\n",
    "    img = image.load_img(fmri_file)\n",
    "    \n",
    "    # 2. Load Events\n",
    "    events_file = os.path.join(base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_events.tsv\")\n",
    "    events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "    \n",
    "    # Filter and map events\n",
    "    events[\"condition\"] = events[\"trial_type\"].apply(map_congruency)\n",
    "    events = events[events[\"condition\"].notna()]\n",
    "    \n",
    "    # 3. Extract Volumes\n",
    "    # We assume the peak BOLD response is ~5 seconds after onset.\n",
    "    # TR = 2.0s, so we look approx 2-3 volumes after onset.\n",
    "    # Simple approach: Take the volume closest to (onset + 5s)\n",
    "    \n",
    "    for _, row in events.iterrows():\n",
    "        onset = row[\"onset\"]\n",
    "        target_time = onset + 5.0 # Hemodynamic delay\n",
    "        target_vol_idx = int(np.round(target_time / TR))\n",
    "        \n",
    "        # Check bounds\n",
    "        if target_vol_idx < img.shape[-1]:\n",
    "            # Extract the single 3D volume\n",
    "            vol = image.index_img(img, target_vol_idx)\n",
    "            fmri_volumes.append(vol)\n",
    "            conditions.append(row[\"condition\"])\n",
    "            run_labels.append(run)\n",
    "\n",
    "print(f\"Total trials extracted: {len(conditions)}\")\n",
    "print(f\"Conditions distribution: {pd.Series(conditions).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069bff8",
   "metadata": {},
   "source": [
    "## 4. Decoding Analysis (SVM)\n",
    "We use `nilearn.decoding.Decoder` to train a Support Vector Machine (SVM).\n",
    "\n",
    "**Setup:**\n",
    "- **Estimator**: SVC (Support Vector Classification).\n",
    "- **Cross-Validation**: Leave-One-Run-Out (Train on Run 1, Test on Run 2, and vice versa).\n",
    "- **Metric**: Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decoder\n",
    "decoder = decoding.Decoder(\n",
    "    estimator='svc',           # Support Vector Classifier\n",
    "    mask=mask_img,             # Brain mask\n",
    "    standardize=True,          # Z-score normalization\n",
    "    scoring='accuracy',        # Evaluation metric\n",
    "    cv=LeaveOneGroupOut(),     # Cross-validation strategy\n",
    "    n_jobs=-1                  # Use all CPUs\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "# X = List of 3D images (fmri_volumes)\n",
    "# y = List of labels (conditions)\n",
    "# groups = List of run IDs (run_labels) for CV splitting\n",
    "\n",
    "print(\"Training SVM classifier...\")\n",
    "decoder.fit(fmri_volumes, conditions, groups=run_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"-\" * 30)\n",
    "print(f\"Classification Accuracy: {np.mean(decoder.cv_scores_['congruent']):.2f}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Chance level is 0.50 (50%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f707eb",
   "metadata": {},
   "source": [
    "## 5. Visualization of Weight Maps\n",
    "The decoder produces a \"weight map\" (coefficients) indicating which voxels contributed most to the decision boundary.\n",
    "- **Positive weights**: Associated with one class (e.g., Incongruent).\n",
    "- **Negative weights**: Associated with the other class (e.g., Congruent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6056e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the weight map (coefficients)\n",
    "# The decoder stores this as a Nifti image\n",
    "weight_img = decoder.coef_img_[\"incongruent\"]\n",
    "\n",
    "# Plot the weights\n",
    "plotting.plot_stat_map(\n",
    "    weight_img, \n",
    "    bg_img=image.mean_img(fmri_volumes[0]), \n",
    "    title=f\"SVM Weights: {subject} (Incongruent vs Congruent)\",\n",
    "    display_mode='z',\n",
    "    cut_coords=[-10, 0, 10, 20, 30]\n",
    ")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dd92d",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "If the accuracy is significantly above 0.50, it suggests that the spatial pattern of brain activity contains information distinguishing the two cognitive states."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
