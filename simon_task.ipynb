{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Simon Task fMRI – First-level GLM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb22364",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Import the necessary libraries for neuroimaging (Nilearn), data manipulation (Pandas, NumPy), and system operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96157f6-9fdf-4577-a4a8-bdd5283f7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn import image, plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681de70a",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Define the dataset root directory, fMRI acquisition parameters (TR), and the runs to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Base directory containing the BIDS-format dataset\n",
    "base_path = \"data/ds101_R2.0.0/\"\n",
    "\n",
    "# Repetition Time (TR) of the fMRI acquisition, in seconds\n",
    "TR = 2.0\n",
    "#The dataset contains two runs per subject\n",
    "runs = [1, 2]\n",
    "\n",
    "print(\"Todo cargó bien\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a7306",
   "metadata": {},
   "source": [
    "## 3. Behavioral Data Inspection\n",
    "Load and inspect the raw event files to understand the distribution of trial types and ensure data integrity across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e940873-6875-481a-8f81-58b78d72ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to behavioral files inside the BIDS dataset\n",
    "events_files = sorted(glob.glob(os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")))\n",
    "\n",
    "all_events = []\n",
    "\n",
    "# Load all behavioral files and concatenate them\n",
    "for f in events_files:\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "    subject = f.split(\"sub-\")[1].split(\"/\")[0]   # extract subject ID\n",
    "    df[\"subject\"] = subject\n",
    "    all_events.append(df)\n",
    "\n",
    "# Combine all subjects into one DataFrame\n",
    "behaviour = pd.concat(all_events, ignore_index=True)\n",
    "\n",
    "# Visualization\n",
    "\n",
    "print(\"Shape of the behavioral dataset:\", behaviour.shape)\n",
    "\n",
    "print(\"\\nTrials per congruency:\")\n",
    "print(behaviour[\"trial_type\"].value_counts())\n",
    "\n",
    "print(\"\\nTrials per subject:\")\n",
    "print(behaviour[\"subject\"].value_counts())\n",
    "\n",
    "# Display first rows for inspection\n",
    "behaviour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f20a7",
   "metadata": {},
   "source": [
    "## 4. Data Preparation Helpers\n",
    "Set up output directories and define helper functions for processing trial types (congruency mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c2448-e537-4f66-b4bb-a1f95d052f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output directory to store the resulting Z maps\n",
    "output_dir = \"first_level_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66661cbf-a1be-4952-8749-f56290dde722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function recode trial types\n",
    "def map_congruency(tt):\n",
    "    \"\"\"\n",
    "    Maps the original trial_type strings to either\n",
    "    \"congruent\" or \"incongruent\" based on keyword matching.\n",
    "    Any other type is discarded (returns None).\n",
    "    \"\"\"\n",
    "    tt = str(tt).lower()\n",
    "    if \"incongruent\" in tt:\n",
    "        return \"incongruent\"\n",
    "    elif \"congruent\" in tt:\n",
    "        return \"congruent\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf85285-dfbf-4399-95d8-b20fde4934bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subjects: sub-01 through sub-21\n",
    "subjects = [f\"sub-{i:02d}\" for i in range(1, 22)]\n",
    "for s in subjects:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fb4d6",
   "metadata": {},
   "source": [
    "## 5. Generate Master Behavioral Dataset\n",
    "Process all subject event files to create a single, cleaned CSV file (`simon_behaviour_clean.csv`). This dataset includes:\n",
    "- Subject and run information.\n",
    "- Trial-level details.\n",
    "- Recoded congruency and accuracy labels.\n",
    "- Binary labels for machine learning (0 = Congruent, 1 = Incongruent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79e021-6fc5-4e41-b1cb-a1d178b03b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavioral master DataFrame clean\n",
    "\n",
    "# This cell:\n",
    "#  - Reads all *_events.tsv files for all subjects\n",
    "#  - Extracts subject, run, trial number\n",
    "#  - Splits trial_type into congruency + accuracy\n",
    "#  - Creates binary label (0 = congruent, 1 = incongruent)\n",
    "#  - Selects only relevant behavioral variables\n",
    "#  - Saves a clean CSV version of the dataset\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Pattern to find all event files for all subjects\n",
    "pattern = os.path.join(base_path, \"sub-*\", \"func\", \"*_events.tsv\")\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "print(\"Number of event files found:\", len(files))\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for f in files:\n",
    "    # Read events file\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "    # Extract subject and run from file path\n",
    "    subject = f.split(\"/\")[-3]      # e.g., \"sub-01\"\n",
    "    run = f.split(\"/\")[-1]          # full file name of the run\n",
    "    \n",
    "    df[\"subject\"] = subject\n",
    "    df[\"run\"] = run\n",
    "    \n",
    "    # Continuous trial number within each run\n",
    "    df[\"trial\"] = range(1, len(df) + 1)\n",
    "    \n",
    "    # Extract congruency and accuracy from trial_type\n",
    "    # Example format: \"congruent_correct\"\n",
    "    df[\"congruency\"] = df[\"trial_type\"].str.split(\"_\").str[0]\n",
    "    df[\"accuracy_label\"] = df[\"trial_type\"].str.split(\"_\").str[1]\n",
    "\n",
    "    # Binary label used for ML:\n",
    "    # 0 = congruent, 1 = incongruent\n",
    "    df[\"label\"] = df[\"congruency\"].map({\"congruent\": 0, \"incongruent\": 1})\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df_clean = df[[\n",
    "        \"subject\",\n",
    "        \"run\",\n",
    "        \"trial\",\n",
    "        \"trial_type\",\n",
    "        \"congruency\",\n",
    "        \"accuracy_label\",\n",
    "        \"correctness\",\n",
    "        \"StimVar\",\n",
    "        \"behav_unlabeled\",\n",
    "        \"Rsponse\",\n",
    "        \"Stimulus\",\n",
    "        \"cond\",\n",
    "        \"label\"\n",
    "    ]]\n",
    "    \n",
    "    all_rows.append(df_clean)\n",
    "\n",
    "# Combine the cleaned datasets\n",
    "behaviour = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Show first rows\n",
    "behaviour.head(20)\n",
    "\n",
    "# Save clean CSV\n",
    "output_csv_path = \"simon_behaviour_clean.csv\"\n",
    "behaviour.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"\\nSaved clean behavioral dataset to:\", output_csv_path)\n",
    "print(\"\\nDataFrame shape:\", behaviour.shape)\n",
    "\n",
    "print(\"\\nTrials per congruency:\")\n",
    "print(behaviour[\"congruency\"].value_counts())\n",
    "\n",
    "print(\"\\nTrials per subject:\")\n",
    "print(behaviour[\"subject\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b6d82-1198-4740-91ca-3a683d6571fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the subjects list is correct\n",
    "subjects = [f\"sub-{i:02d}\" for i in range(1, 22)]\n",
    "print(\"Subjects that will be processed:\", subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75dd3bf",
   "metadata": {},
   "source": [
    "## 6. Data Loading Verification (Dry Run)\n",
    "Iterate through all subjects to verify that fMRI images and event files can be correctly loaded and that design matrices can be constructed without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fa1ae-c563-41cf-97e3-671d59989797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN LOOP OVER SUBJECTS\n",
    "print(\"Subjects to be processed:\", subjects)\n",
    "\n",
    "for subject in subjects:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Processing:\", subject)\n",
    "    print(\"yeaaaahhh\")\n",
    "\n",
    "    # Lists to store fMRI images and design matrices across the two runs\n",
    "    fmri_imgs = []\n",
    "    design_matrices = []\n",
    "\n",
    "    # Loop through both runs\n",
    "    for run in runs:\n",
    "        # Load preprocessed fMRI BOLD image\n",
    "        fmri_file = os.path.join(\n",
    "            base_path,\n",
    "            subject,\n",
    "            \"func\",\n",
    "            f\"{subject}_task-simon_run-{run}_bold.nii.gz\"\n",
    "        )\n",
    "        img = image.load_img(fmri_file)\n",
    "        fmri_imgs.append(img)\n",
    "\n",
    "        # Determine number of volumes (scans) in the run\n",
    "        n_scans = img.shape[-1]\n",
    "\n",
    "        # Define frame times in seconds using the TR\n",
    "        frame_times = np.arange(n_scans) * TR\n",
    "\n",
    "        # Load and recode events file\n",
    "        events_file = os.path.join(\n",
    "            base_path,\n",
    "            subject,\n",
    "            \"func\",\n",
    "            f\"{subject}_task-simon_run-{run}_events.tsv\"\n",
    "        )\n",
    "        events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "\n",
    "        # Apply congruency recoding\n",
    "        events[\"trial_type\"] = events[\"trial_type\"].apply(map_congruency)\n",
    "\n",
    "        # Remove trials that are not congruent or incongruent\n",
    "        events = events[events[\"trial_type\"].notna()]\n",
    "\n",
    "        # Build design matrix for this run\n",
    "        design = make_first_level_design_matrix(\n",
    "            frame_times=frame_times,\n",
    "            events=events,\n",
    "            hrf_model=\"glover\",     # Hemodynamic Response Function model\n",
    "            drift_model=\"cosine\",   # Drift model for low-frequency noise\n",
    "            high_pass=0.01          # High-pass filter cutoff (Hz)\n",
    "        )\n",
    "        design_matrices.append(design)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c6357",
   "metadata": {},
   "source": [
    "## 6.1 Individual Run Diagnostics (sub-01)\n",
    "Before running the analysis for all subjects, we perform a detailed diagnostic analysis on a single subject (`sub-01`). This step helps ensure data quality by:\n",
    "1.  Fitting the GLM to each run independently.\n",
    "2.  Visualizing the activation maps for each run to check for consistency and artifacts.\n",
    "3.  Verifying that the contrast `incongruent > congruent` yields expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07266f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subject for diagnostics\n",
    "subject = \"sub-01\"\n",
    "print(f\"Running diagnostics for {subject}...\")\n",
    "\n",
    "# Lists to store images and designs for the diagnostic runs\n",
    "diag_imgs = []\n",
    "diag_designs = []\n",
    "\n",
    "for run in runs:\n",
    "    # Load fMRI image\n",
    "    fmri_file = os.path.join(base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_bold.nii.gz\")\n",
    "    img = image.load_img(fmri_file)\n",
    "    diag_imgs.append(img)\n",
    "    \n",
    "    # Load and process events\n",
    "    events_file = os.path.join(base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_events.tsv\")\n",
    "    events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "    events[\"trial_type\"] = events[\"trial_type\"].apply(map_congruency)\n",
    "    events = events[events[\"trial_type\"].notna()]\n",
    "    \n",
    "    # Create design matrix\n",
    "    n_scans = img.shape[-1]\n",
    "    frame_times = np.arange(n_scans) * TR\n",
    "    design = make_first_level_design_matrix(\n",
    "        frame_times=frame_times, \n",
    "        events=events, \n",
    "        hrf_model=\"glover\", \n",
    "        drift_model=\"cosine\", \n",
    "        high_pass=0.01\n",
    "    )\n",
    "    diag_designs.append(design)\n",
    "    print(f\"Loaded Run {run}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12195095",
   "metadata": {},
   "source": [
    "### 6.1.3 Analyze Run 2\n",
    "Fit the GLM for the second run and visualize the contrast `incongruent > congruent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GLM for Run 2\n",
    "print(\"Fitting Run 2...\")\n",
    "glm_run2 = FirstLevelModel(t_r=TR, smoothing_fwhm=5.0, minimize_memory=True)\n",
    "glm_run2.fit(diag_imgs[1], design_matrices=diag_designs[1])\n",
    "\n",
    "# Compute and visualize contrast\n",
    "z_map_run2 = glm_run2.compute_contrast(\"incongruent - congruent\")\n",
    "plotting.plot_stat_map(z_map_run2, title=f\"{subject} Run 2: Incongruent > Congruent\", threshold=3.0)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b74e9",
   "metadata": {},
   "source": [
    "### 6.1.2 Analyze Run 1\n",
    "Fit the GLM for the first run and visualize the contrast `incongruent > congruent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1936b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GLM for Run 1\n",
    "print(\"Fitting Run 1...\")\n",
    "glm_run1 = FirstLevelModel(t_r=TR, smoothing_fwhm=5.0, minimize_memory=True)\n",
    "glm_run1.fit(diag_imgs[0], design_matrices=diag_designs[0])\n",
    "\n",
    "# Compute and visualize contrast\n",
    "z_map_run1 = glm_run1.compute_contrast(\"incongruent - congruent\")\n",
    "plotting.plot_stat_map(z_map_run1, title=f\"{subject} Run 1: Incongruent > Congruent\", threshold=3.0)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ec399",
   "metadata": {},
   "source": [
    "## 7. First-Level GLM Analysis (Joint Model)\n",
    "Perform the General Linear Model (GLM) analysis for each subject using a **Joint Model** approach (fitting both runs simultaneously).\n",
    "\n",
    "**Analysis Strategy:**\n",
    "1.  **Joint Fitting**: Both runs are fitted at once to maximize statistical power.\n",
    "2.  **Expanded Contrasts**: We compute multiple contrasts (e.g., `incongruent`, `congruent`, `incongruent > congruent`) to explore the data fully.\n",
    "3.  **HTML Reporting**: For each subject, we generate an interactive HTML report containing design matrices, correlation matrices, and statistical maps.\n",
    "\n",
    "**Steps:**\n",
    "1.  Load data and construct design matrices for all runs.\n",
    "2.  Fit the `FirstLevelModel`.\n",
    "3.  Generate and save the HTML report.\n",
    "4.  Compute and save Z-maps for all defined contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30964e67-658c-4961-8653-972b293df7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories\n",
    "output_dir = \"first_level_results\"\n",
    "reports_dir = \"first_level_reports\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "print(\"Output directory:\", os.path.abspath(output_dir))\n",
    "print(\"Reports directory:\", os.path.abspath(reports_dir))\n",
    "\n",
    "# Define dictionary of contrasts to compute\n",
    "# We include T-contrasts for specific conditions and differences, \n",
    "# and we will add an F-contrast for effects of interest dynamically.\n",
    "contrasts = {\n",
    "    \"incongruent_vs_congruent\": \"incongruent - congruent\",\n",
    "    \"congruent_vs_incongruent\": \"congruent - incongruent\",\n",
    "    \"incongruent\": \"incongruent\",\n",
    "    \"congruent\": \"congruent\",\n",
    "    \"task_activation\": \"incongruent + congruent\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a4280",
   "metadata": {},
   "source": [
    "### 7.1 Execute Analysis Loop\n",
    "Iterate through all subjects, fit the joint GLM, generate reports, and save statistical maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all subjects\n",
    "for subject in subjects:\n",
    "    print(f\"\\nProcessing {subject}...\")\n",
    "    \n",
    "    fmri_imgs = []\n",
    "    design_matrices = []\n",
    "\n",
    "    # 1. Load Data for all runs\n",
    "    for run in runs:\n",
    "        # Load fMRI image\n",
    "        fmri_file = os.path.join(\n",
    "            base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_bold.nii.gz\"\n",
    "        )\n",
    "        img = image.load_img(fmri_file)\n",
    "        fmri_imgs.append(img)\n",
    "\n",
    "        # Define frame times\n",
    "        n_scans = img.shape[-1]\n",
    "        frame_times = np.arange(n_scans) * TR\n",
    "\n",
    "        # Load and process events\n",
    "        events_file = os.path.join(\n",
    "            base_path, subject, \"func\", f\"{subject}_task-simon_run-{run}_events.tsv\"\n",
    "        )\n",
    "        events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "        events[\"trial_type\"] = events[\"trial_type\"].apply(map_congruency)\n",
    "        events = events[events[\"trial_type\"].notna()]\n",
    "\n",
    "        # Construct design matrix\n",
    "        design = make_first_level_design_matrix(\n",
    "            frame_times=frame_times,\n",
    "            events=events,\n",
    "            hrf_model=\"glover\",\n",
    "            drift_model=\"cosine\",\n",
    "            high_pass=0.01\n",
    "        )\n",
    "        design_matrices.append(design)\n",
    "\n",
    "    # 2. Add F-test for Effects of Interest\n",
    "    # Dynamically select the first two columns (conditions) for the F-test\n",
    "    n_columns = design_matrices[0].shape[1]\n",
    "    contrasts[\"effects_of_interest\"] = np.eye(n_columns)[:2]\n",
    "\n",
    "    # 3. Fit Joint GLM (fitting both runs simultaneously)\n",
    "    glm = FirstLevelModel(\n",
    "        t_r=TR,\n",
    "        smoothing_fwhm=5.0,\n",
    "        minimize_memory=True,\n",
    "        n_jobs=-1\n",
    "    ).fit(\n",
    "        fmri_imgs,\n",
    "        design_matrices=design_matrices\n",
    "    )\n",
    "\n",
    "    # 4. Generate HTML Report\n",
    "    print(f\"  Generating report for {subject}...\")\n",
    "    mean_img = image.mean_img(fmri_imgs[0]) # Background image\n",
    "    \n",
    "    report = glm.generate_report(\n",
    "        contrasts,\n",
    "        title=f\"GLM Report for {subject}\",\n",
    "        bg_img=mean_img\n",
    "    )\n",
    "    report.save_as_html(os.path.join(reports_dir, f\"report_{subject}.html\"))\n",
    "\n",
    "    # 5. Compute and Save Contrasts\n",
    "    for contrast_id, contrast_val in contrasts.items():\n",
    "        print(f\"  Computing contrast: {contrast_id}\")\n",
    "        z_map = glm.compute_contrast(\n",
    "            contrast_val,\n",
    "            output_type=\"z_score\"\n",
    "        )\n",
    "        \n",
    "        out_path = os.path.join(\n",
    "            output_dir,\n",
    "            f\"{subject}_zmap_{contrast_id}.nii.gz\"\n",
    "        )\n",
    "        z_map.to_filename(out_path)\n",
    "        \n",
    "print(\"\\nAnalysis complete. Check 'first_level_reports' for HTML reports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdc148",
   "metadata": {},
   "source": [
    "## 8. Results Visualization\n",
    "Inspect the generated output files and visualize the results for a representative subject (e.g., `sub-01`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef3ca4-74e2-43c9-8d42-759fd9a61bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files in first_level_results:\")\n",
    "for f in sorted(os.listdir(\"first_level_results\")):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d0caf",
   "metadata": {},
   "source": [
    "### 8.1 Z-Map Visualization\n",
    "Plot the statistical map (Z-score) on a standard brain template to visualize regions with significant activation differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cac4b-187c-4b95-8631-b701a415f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one example Z-MAP\n",
    "example_subject = \"sub-01\"\n",
    "\n",
    "example_file = os.path.join(\n",
    "    output_dir,\n",
    "    f\"{example_subject}_zmap_incongruent_vs_congruent.nii.gz\"\n",
    ")\n",
    "\n",
    "z_map_example = image.load_img(example_file)\n",
    "\n",
    "plotting.plot_stat_map(\n",
    "    z_map_example,\n",
    "    title=f\"{example_subject}: incongruent > congruent (Z-map)\",\n",
    "    threshold=3.0\n",
    ")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0a0d1",
   "metadata": {},
   "source": [
    "### 8.2 Axial Slice View\n",
    "Extract and display the central axial slice of the Z-map as a 2D matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819a40a-9c54-4ac8-9ac2-0798ea0be6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize central axial slice as 2D Matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "\n",
    "# Choose one example subject\n",
    "example_subject = \"sub-01\"\n",
    "\n",
    "# Path to the subject's Z-map\n",
    "example_file = os.path.join(\n",
    "    output_dir,\n",
    "    f\"{example_subject}_zmap_incongruent_vs_congruent.nii.gz\"\n",
    ")\n",
    "\n",
    "# Load the Z-map image\n",
    "z_map_example = image.load_img(example_file)\n",
    "\n",
    "# Get the 3D data array (x, y, z)\n",
    "data = z_map_example.get_fdata()\n",
    "\n",
    "# Compute the index of the central axial slice\n",
    "# Axis 2 corresponds to the z-dimension (axial)\n",
    "slice_idx = data.shape[2] // 2\n",
    "\n",
    "# Extract the central axial slice\n",
    "central_slice = data[:, :, slice_idx]\n",
    "\n",
    "print(\"Z-map shape:\", data.shape)\n",
    "print(\"Central slice index (z-axis):\", slice_idx)\n",
    "\n",
    "# Plot the slice as a 2D matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(central_slice, origin=\"lower\")\n",
    "plt.colorbar(label=\"Z value\")\n",
    "plt.title(f\"{example_subject} - Central axial slice (incongruent > congruent)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328530c",
   "metadata": {},
   "source": [
    "### 8.3 Z-Value Distribution\n",
    "Plot a histogram of the Z-values to analyze the distribution of statistical scores across the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Z values\n",
    "\n",
    "# Flatten the 3D array into 1D\n",
    "z_values = data.flatten()\n",
    "\n",
    "# Keep only finite values (avoid NaNs or infs)\n",
    "z_values = z_values[np.isfinite(z_values)]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(z_values, bins=60)\n",
    "plt.xlabel(\"Z value\")\n",
    "plt.ylabel(\"Number of voxels\")\n",
    "plt.title(f\"{example_subject} - Z-value distribution (incongruent > congruent)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, image\n",
    "%matplotlib inline\n",
    "# Load the first subject's first run\n",
    "img_path = \"data/ds101_R2.0.0/sub-04/func/sub-04_task-simon_run-1_bold.nii.gz\"\n",
    "\n",
    "# Compute the mean image (average over time)\n",
    "mean_img = image.mean_img(img_path)\n",
    "\n",
    "# Plot it\n",
    "plotting.plot_anat(mean_img, title=\"Check for Skull & Eyes\")\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurocomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
